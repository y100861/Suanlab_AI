{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyjyu4FzUAVw"
      },
      "source": [
        "# 신경망 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQvNez4qydhL"
      },
      "source": [
        "## 단순한 신경망 구현 : Logic Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7te43hqyiiJ"
      },
      "source": [
        "### 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Qf2F_YbdybBE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use([\"seaborn-whitegrid\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "orUoPmDcymhj"
      },
      "source": [
        "### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "bOAmMxo0ymDF"
      },
      "outputs": [],
      "source": [
        "lr = 0.1\n",
        "epochs = 1000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BjmLWgFVysnq"
      },
      "source": [
        "### 유틸 함수들(Util Functions)\n",
        "$\\left(\\frac{\\partial f}{\\partial x_0},\\frac{\\partial f}{\\partial x_1}\\right) (∂f∂x0​​,∂f∂x1​​)  $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Y4OMFGrjyq1c"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    c = np.max(x)\n",
        "    exp_x = np.exp(x - c)\n",
        "    sum_exp_x = np.sum(exp_x)\n",
        "    return exp_x / sum_exp_x\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "    delta = 1e-7\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum(true_y * np.log(pred_y + delta))\n",
        "\n",
        "def cross_entropy_error_for_bin(pred_y, true_y):\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum((true_y * np.log(pred_y), (1 - true_y) * np.log(1 - pred_y)))\n",
        "\n",
        "def cross_entropy_error_for_batch(pred_y, true_y):\n",
        "    delta = 1e-7\n",
        "    batch_size = pred_y.shape[0]\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "    return np.mean(np.square(true_y - pred_y))\n",
        "\n",
        "def differential_1d(f, x):\n",
        "    eps = 1e-5\n",
        "    diff_value = np.zeros_like(x)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        temp_val = x[i]\n",
        "\n",
        "        x[i] = temp_val + eps\n",
        "        f_h1 = f(x)\n",
        "\n",
        "        x[i] = temp_val - eps\n",
        "        f_h2 = f(x)\n",
        "\n",
        "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "        x[i] = temp_val\n",
        "    \n",
        "    return diff_value\n",
        "\n",
        "def differential_2d(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return differential_1d(f, X)\n",
        "    else:\n",
        "        grads = np.zeros_like(X)\n",
        "\n",
        "        for idx, x in enumerate(X):\n",
        "            grads[idx] = differential_1d(f, x)\n",
        "        \n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Z2LTT_y3i5"
      },
      "source": [
        "### 신경망"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "gMTjjYgdy3D8"
      },
      "outputs": [],
      "source": [
        "class LogicGateNet():\n",
        "\n",
        "    def __init__(self, input_nodes, output_units):\n",
        "        # 가중치 및 편향 생성\n",
        "        def weight_init(input_nodes, output_units):\n",
        "            np.random.seed(1)\n",
        "            params = {}\n",
        "            params[\"w_1\"] = np.random.randn(input_nodes * output_units) # np.random.randn(a) => 1차원으로 a개의 랜덤한 정규분포 수들을 추출 / np.random.randn(a, b) => (a, b)배열의 2차원으로 랜덤한 정규분포 수들을 추출\n",
        "            params[\"b_1\"] = np.random.rand(output_units)\n",
        "            return params\n",
        "        \n",
        "        self.params = weight_init(input_nodes, output_units)\n",
        "\n",
        "    # 예측값 생성\n",
        "    def predict(self, x):\n",
        "        W_1 = self.params[\"w_1\"].reshape(-1, 1)\n",
        "        B_1 = self.params[\"b_1\"]\n",
        "        pred_y = sigmoid(np.dot(x, W_1) + B_1)\n",
        "        return pred_y\n",
        "\n",
        "    # 손실(오차) 생성\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "        \n",
        "    # 기울기 생성\n",
        "    def get_gradient(self, x, true_y):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, true_y)\n",
        "        \n",
        "        grads = {}\n",
        "        grads[\"w_1\"] = differential_1d(loss_grad, self.params[\"w_1\"])\n",
        "        grads[\"b_1\"] = differential_1d(loss_grad, self.params[\"b_1\"])\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNDoH_3zbGZ"
      },
      "source": [
        "### AND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P-ib8_RzHTh"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "rRiaACA6zGom"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 0.9879373568735578, Gradient: [2.01503856 1.71662117], Bias: [-3.08282757]\n",
            "Epoch: 200, Cost: 0.6506687590545478, Gradient: [2.79693855 2.73539701], Bias: [-4.37630256]\n",
            "Epoch: 300, Cost: 0.4860468400349507, Gradient: [3.40228815 3.3848267 ], Bias: [-5.29773137]\n",
            "Epoch: 400, Cost: 0.3868848037166772, Gradient: [3.8824553  3.87626796], Bias: [-6.01648561]\n",
            "Epoch: 500, Cost: 0.3205891407037802, Gradient: [4.27734849 4.27477562], Bias: [-6.60554348]\n",
            "Epoch: 600, Cost: 0.27322844972348626, Gradient: [4.61168928 4.6104836 ], Bias: [-7.10408809]\n",
            "Epoch: 700, Cost: 0.23776988486634595, Gradient: [4.9011229  4.90050339], Bias: [-7.5358348]\n",
            "Epoch: 800, Cost: 0.21026996938492645, Gradient: [5.15603123 5.15568883], Bias: [-7.91628056]\n",
            "Epoch: 900, Cost: 0.18834642177042332, Gradient: [5.38361567 5.38341492], Bias: [-8.25611777]\n",
            "Epoch: 1000, Cost: 0.17047648607833352, Gradient: [5.58906188 5.58893832], Bias: [-8.56303389]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_1 = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "AND = LogicGateNet(input_nodes=X.shape[1], output_units=Y_1.shape[1])\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = AND.get_gradient(X, Y_1)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        AND.params[key] -= lr * grads[key]\n",
        "    \n",
        "    loss = AND.loss(X, Y_1)\n",
        "    \n",
        "    if i % 100 == 99:\n",
        "        print(\"Epoch: {}, Cost: {}, Gradient: {}, Bias: {}\".format(i + 1, loss, AND.params[\"w_1\"].reshape(-1, ), AND.params[\"b_1\"].reshape(-1, )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoyQv_czT7R"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "-7CvWgc9zREa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.91002335e-04]\n",
            " [4.86099648e-02]\n",
            " [4.86156795e-02]\n",
            " [9.31818598e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(AND.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMXNiXWzts-"
      },
      "source": [
        "### OR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ79pc4jzw3O"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "8gnLmAyQzuoL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 0.6786576335658816, Gradient: [2.98831871 2.39880239], Bias: [-0.67875835]\n",
            "Epoch: 200, Cost: 0.4120065907316995, Gradient: [3.85457519 3.61235159], Bias: [-1.30773792]\n",
            "Epoch: 300, Cost: 0.2929230206606818, Gradient: [4.51092321 4.38480447], Bias: [-1.70090032]\n",
            "Epoch: 400, Cost: 0.22594941843677072, Gradient: [5.02588551 4.94993214], Bias: [-1.98818437]\n",
            "Epoch: 500, Cost: 0.1833052982705829, Gradient: [5.44543336 5.39513131], Bias: [-2.21445381]\n",
            "Epoch: 600, Cost: 0.15390070356223973, Gradient: [5.79774684 5.76215647], Bias: [-2.40088812]\n",
            "Epoch: 700, Cost: 0.13245996247876582, Gradient: [6.10062111 6.0741922 ], Bias: [-2.55926578]\n",
            "Epoch: 800, Cost: 0.11616495526038, Gradient: [6.3658123  6.34545117], Bias: [-2.69682842]\n",
            "Epoch: 900, Cost: 0.10337885508874566, Gradient: [6.60142242 6.58527659], Bias: [-2.81834678]\n",
            "Epoch: 1000, Cost: 0.0930883806927856, Gradient: [6.81324253 6.80013851], Bias: [-2.9271287]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_2 = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "OR = LogicGateNet(input_nodes=X.shape[1], output_units=Y_2.shape[1])\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = OR.get_gradient(X, Y_2)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        OR.params[key] -= lr * grads[key]\n",
        "    \n",
        "    loss = OR.loss(X, Y_2)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\"Epoch: {}, Cost: {}, Gradient: {}, Bias: {}\".format(i + 1, loss, OR.params[\"w_1\"].reshape(-1, ), OR.params[\"b_1\"].reshape(-1, )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWmEtX_VnLSI"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "JwPpOs3-z2vU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.05082867]\n",
            " [0.97962797]\n",
            " [0.97988785]\n",
            " [0.99997714]]\n"
          ]
        }
      ],
      "source": [
        "print(OR.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEBhczCIz57Q"
      },
      "source": [
        "### NAND Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzQaaHKKz8sZ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "h463QUQRz8PS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 1.0843477603747682, Weights: [-1.52038477 -1.8044596 ], Bias: [2.79613861]\n",
            "Epoch: 200, Cost: 0.6902784247155889, Weights: [-2.61076184 -2.66551134], Bias: [4.18950611]\n",
            "Epoch: 300, Cost: 0.5080628196571597, Weights: [-3.29126404 -3.30609336], Bias: [5.15778594]\n",
            "Epoch: 400, Cost: 0.4009142794906003, Weights: [-3.80128706 -3.80637256], Bias: [5.90451903]\n",
            "Epoch: 500, Cost: 0.3302901304973989, Weights: [-4.21231761 -4.21438224], Bias: [6.51232147]\n",
            "Epoch: 600, Cost: 0.2803201967667349, Weights: [-4.55704426 -4.55799437], Bias: [7.02432061]\n",
            "Epoch: 700, Cost: 0.24317000579159848, Weights: [-4.85385997 -4.85434129], Bias: [7.46619134]\n",
            "Epoch: 800, Cost: 0.21451287067550753, Weights: [-5.11434269 -5.11460572], Bias: [7.85452518]\n",
            "Epoch: 900, Cost: 0.19176409008017314, Weights: [-5.34630895 -5.34646174], Bias: [8.20067666]\n",
            "Epoch: 1000, Cost: 0.17328577069498524, Weights: [-5.55529987 -5.55539319], Bias: [8.51275788]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_3 = np.array([[1], [1], [1], [0]])\n",
        "\n",
        "NAND = LogicGateNet(input_nodes=X.shape[1], output_units=Y_3.shape[1])\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = NAND.get_gradient(X, Y_3)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        NAND.params[key] -= lr * grads[key]\n",
        "    \n",
        "    loss = NAND.loss(X, Y_3)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, NAND.params[\"w_1\"].reshape(-1, ), NAND.params[\"b_1\"].reshape(-1, )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR-rHaTU0Mga"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "WpzKW6sm0Ghp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.99979915]\n",
            " [0.95061041]\n",
            " [0.95061479]\n",
            " [0.06927143]]\n"
          ]
        }
      ],
      "source": [
        "print(NAND.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTWfSQ60Zl2"
      },
      "source": [
        "### XOR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmmL0VIu0bXq"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "0CGm0r1M0a9M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 2.775810299574745, Weights: [ 0.15549717 -0.03283867], Bias: [-0.0727685]\n",
            "Epoch: 200, Cost: 2.772645288796451, Weights: [0.0201055  0.00512345], Bias: [-0.01496259]\n",
            "Epoch: 300, Cost: 2.7725906094087485, Weights: [0.00318944 0.0019981 ], Bias: [-0.00307658]\n",
            "Epoch: 400, Cost: 2.772588798836752, Weights: [0.00058069 0.00048596], Bias: [-0.0006326]\n",
            "Epoch: 500, Cost: 2.7725887254580046, Weights: [0.00011343 0.00010589], Bias: [-0.00013007]\n",
            "Epoch: 600, Cost: 2.7725887223757146, Weights: [2.28475138e-05 2.22485217e-05], Bias: [-2.67451295e-05]\n",
            "Epoch: 700, Cost: 2.772588722245527, Weights: [4.66006228e-06 4.61244243e-06], Bias: [-5.49923334e-06]\n",
            "Epoch: 800, Cost: 2.772588722240024, Weights: [9.55176997e-07 9.51404291e-07], Bias: [-1.13073444e-06]\n",
            "Epoch: 900, Cost: 2.7725887222397914, Weights: [1.96157483e-07 1.95873098e-07], Bias: [-2.32497405e-07]\n",
            "Epoch: 1000, Cost: 2.7725887222397816, Weights: [4.03132567e-08 4.02975452e-08], Bias: [-4.78051432e-08]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_4 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "XOR = LogicGateNet(input_nodes=X.shape[1], output_units=Y_4.shape[1])\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = XOR.get_gradient(X, Y_4)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        XOR.params[key] -= lr * grads[key]\n",
        "    \n",
        "    loss = XOR.loss(X, Y_4)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, XOR.params[\"w_1\"].reshape(-1, ), XOR.params[\"b_1\"].reshape(-1, )))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-ktElI0o5P"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "GWAJAJ_T0oqm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.49999999]\n",
            " [0.5       ]\n",
            " [0.5       ]\n",
            " [0.50000001]]\n"
          ]
        }
      ],
      "source": [
        "print(XOR.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlq_-6E1nIq"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(1)\n",
        "\n",
        "- 얕은 신경망, Shallow Neural Network\n",
        "\n",
        "- 두 논리게이트(NAND, OR)를 통과하고  \n",
        "  AND 게이트로 합쳐서 구현\n",
        "\n",
        "- 06 신경망 구조 참고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "mr7nYMG20jTo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.99979915, 0.05082867],\n",
              "       [0.95061041, 0.97962797],\n",
              "       [0.95061479, 0.97988785],\n",
              "       [0.06927143, 0.99997714]])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_5 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "s1 = NAND.predict(X)\n",
        "s2 = OR.predict(X)\n",
        "X_2 = np.c_[s1, s2]\n",
        "X_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTDx8Ah1xHY"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "LK2iD5A91yWQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.06350555]\n",
            " [0.90247804]\n",
            " [0.90260795]\n",
            " [0.06997581]]\n"
          ]
        }
      ],
      "source": [
        "print(AND.predict(X_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-SK4G262Agn"
      },
      "source": [
        "#### 2층 신경망으로 XOR 게이트 구현(2)\n",
        "- 클래스로 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "8RpnHCRZ1zwr"
      },
      "outputs": [],
      "source": [
        "class XORNet():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # 가중치 및 편향 생성\n",
        "        def weight_init():\n",
        "            np.random.seed(1)\n",
        "            params = {}\n",
        "            params[\"w_1\"] = np.random.randn(2)\n",
        "            params[\"b_1\"] = np.zeros(2)\n",
        "            params[\"w_2\"] = np.random.randn(2)\n",
        "            params[\"b_2\"] = np.zeros(1)\n",
        "            return params\n",
        "        \n",
        "        # 2층 신경망으로 구성\n",
        "        self.params = weight_init()\n",
        "    \n",
        "    # 예측값 생성\n",
        "    def predict(self, x):\n",
        "        W_1, W_2 = self.params[\"w_1\"].reshape(-1, 1), self.params[\"w_2\"].reshape(-1, 1)\n",
        "        B_1, B_2 = self.params[\"b_1\"], self.params[\"b_2\"]\n",
        "\n",
        "        A1 = np.dot(x, W_1) + B_1\n",
        "        Z1 = sigmoid(A1)\n",
        "\n",
        "        A2 = np.dot(Z1, W_2) + B_2\n",
        "        pred_y = sigmoid(A2)\n",
        "        return pred_y\n",
        "    \n",
        "    # 손실(오차) 생성\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_error_for_bin(pred_y, true_y)\n",
        "    \n",
        "    # 기울기 생성\n",
        "    def get_gradient(self, x, true_y):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, true_y)\n",
        "        \n",
        "        grads = {}\n",
        "        grads[\"w_1\"] = differential_2d(loss_grad, self.params[\"w_1\"])\n",
        "        grads[\"w_2\"] = differential_2d(loss_grad, self.params[\"w_2\"])\n",
        "        grads[\"b_1\"] = differential_2d(loss_grad, self.params[\"b_1\"])\n",
        "        grads[\"b_2\"] = differential_2d(loss_grad, self.params[\"b_2\"])\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.80217284 -0.44887781]]\n"
          ]
        }
      ],
      "source": [
        "a = np.random.randn(1, 2)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lplK_x0l2YLh"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)\n",
        "- 재조정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "qf-3wWSv2b7l"
      },
      "outputs": [],
      "source": [
        "lr = 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHKd45d2JbJ"
      },
      "source": [
        "#### 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "cQNd3XVd2Gj7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100, Cost: 2.663783038416127, Weights: (array([ 2.31714726, -1.42567368]), array([-0.0017465 , -1.18730127])), Bias: (array([0.15275705, 0.98776375]), array([0.85106587]))\n",
            "Epoch: 200, Cost: 0.9526283824161293, Weights: (array([ 4.10287848, -4.37106997]), array([ 3.72906674, -3.92370088])), Bias: (array([-2.00699021,  2.47472511]), array([1.80665456]))\n",
            "Epoch: 300, Cost: 0.27773538322470437, Weights: (array([ 5.57959884, -5.76491213]), array([ 6.4760945 , -6.14241619])), Bias: (array([-2.85133424,  2.9812897 ]), array([2.76310621]))\n",
            "Epoch: 400, Cost: 0.1526861761737508, Weights: (array([ 6.1443265 , -6.29184616]), array([ 7.65898747, -7.25386579])), Bias: (array([-3.1528817 ,  3.19865241]), array([3.30425121]))\n",
            "Epoch: 500, Cost: 0.10396375609391117, Weights: (array([ 6.47108487, -6.59780266]), array([ 8.40164484, -7.97469628])), Bias: (array([-3.32482777,  3.33185343]), array([3.66307845]))\n",
            "Epoch: 600, Cost: 0.07845245187103636, Weights: (array([ 6.6955996 , -6.80886039]), array([ 8.94156593, -8.50534894])), Bias: (array([-3.4420609 ,  3.42624024]), array([3.92928241]))\n",
            "Epoch: 700, Cost: 0.0628566857148467, Weights: (array([ 6.8644833 , -6.96816878]), array([ 9.36530329, -8.92442899])), Bias: (array([-3.52980941,  3.49864639]), array([4.14026465]))\n",
            "Epoch: 800, Cost: 0.05236957280863757, Weights: (array([ 6.99879724, -7.095235  ]), array([ 9.71384217, -9.27038914])), Bias: (array([-3.59935185,  3.55703162]), array([4.31476603]))\n",
            "Epoch: 900, Cost: 0.04484790357835372, Weights: (array([ 7.10971727, -7.2004272 ]), array([10.00977301, -9.56480792])), Bias: (array([-3.65663041,  3.60574955]), array([4.46343397]))\n",
            "Epoch: 1000, Cost: 0.03919612527668971, Weights: (array([ 7.20383745, -7.28987459]), array([10.26685392, -9.82097501])), Bias: (array([-3.70513277,  3.64742589]), array([4.59287409]))\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) # 입력값\n",
        "Y_5 = np.array([[0], [1], [1], [0]]) # 입력값에 대한 레이블\n",
        "\n",
        "XOR = XORNet()\n",
        "\n",
        "for i in range(epochs):\n",
        "    grads = XOR.get_gradient(X, Y_5)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        XOR.params[key] -= lr * grads[key]\n",
        "    \n",
        "    loss = XOR.loss(X, Y_5) # 입력값에 대한 예측값과 레이블 간의 손실(오차)\n",
        "\n",
        "    if i % 100 == 99:\n",
        "        print(\"Epoch: {}, Cost: {}, Weights: {}, Bias: {}\".format(i+1, loss, (XOR.params[\"w_1\"], XOR.params[\"w_2\"]), (XOR.params[\"b_1\"], XOR.params[\"b_2\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIV_GsoG2eDs"
      },
      "source": [
        "#### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Dpr0nZhc2Szr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.00873007]\n",
            " [0.9871619 ]\n",
            " [0.9913166 ]\n",
            " [0.0087467 ]]\n"
          ]
        }
      ],
      "source": [
        "print(XOR.predict(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1IuDL8R7wrx"
      },
      "source": [
        "## 다중 클래스 분류 : MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CiJ5Gmq9Wpa"
      },
      "source": [
        "### 배치 처리\n",
        "- 학습 데이터 전체를 한번에 진행하지 않고  \n",
        "  일부 데이터(샘플)을 확률적으로 구해서 조금씩 나누어 진행\n",
        "\n",
        "- 확률적 경사 하강법(Stochastic Gradient Descent) 또는  \n",
        "  미니 배치 학습법(mini-batch learning)이라고도 부름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUDNWwj49byH"
      },
      "source": [
        "#### 신경망 구현 : MNIST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjBRQYlP74GM"
      },
      "source": [
        "#### 필요한 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "h0lJbkuW71lm"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "import time\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDvtEiD77_gu"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "4WL7zXMl_uo9"
      },
      "outputs": [],
      "source": [
        "mnist = tensorflow.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_rNg5Jn8FRA"
      },
      "source": [
        "#### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "u4wpsQGA8BOO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "pU7nvkHO8IFR"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_train[0], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "WbBA1Kl18KGT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTFu8i-z8U_C"
      },
      "source": [
        "#### 데이터 전처리 (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_for_mnist(data):\n",
        "    temp = np.zeros((data.shape[0], data[0].size))\n",
        "\n",
        "    for idx, data in enumerate(data):\n",
        "        temp[idx, :] = data.flatten()\n",
        "\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "q76pjKDVftHJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n",
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "# 정규화\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_ohe, y_test_ohe = tensorflow.one_hot(y_train, depth=10).numpy(), tensorflow.one_hot(y_test, depth=10).numpy()\n",
        "print(y_train_ohe.shape)\n",
        "print(y_test_ohe.shape)\n",
        "\n",
        "# 28*28 데이터를 평탄화\n",
        "x_train = flatten_for_mnist(x_train)\n",
        "x_test = flatten_for_mnist(x_test)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "9LjpWz0dotJs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 0.0\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0].max(), x_train[0].min())\n",
        "print(y_train_ohe[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUaa92Y9RhY"
      },
      "source": [
        "#### 하이퍼 파라미터(Hyper Parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "sk3FXXLi9Th5"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "lr = 0.1\n",
        "batch_size = 100\n",
        "train_size = x_train.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lMJ0h8p8iZl"
      },
      "source": [
        "#### 사용되는 함수들(Util Functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "bSlqZ2Xx8hFn"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    c = np.max(x)\n",
        "    exp_x = np.exp(x - c)\n",
        "    sum_exp_x = np.sum(exp_x)\n",
        "    return exp_x / sum_exp_x\n",
        "\n",
        "def cross_entropy_error(pred_y, true_y):\n",
        "    delta = 1e-7\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum((true_y * np.log(pred_y + delta)))\n",
        "\n",
        "def cross_entropy_error_for_bin(pred_y, true_y):\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum((true_y * np.log(pred_y), (1 - true_y) * np.log(1 - pred_y)))\n",
        "\n",
        "def cross_entropy_error_for_batch(pred_y, true_y):\n",
        "    delta = 1e-7\n",
        "    batch_size = pred_y.shape[0]\n",
        "    if true_y.ndim == 1:\n",
        "        pred_y = pred_y.reshape(-1, 1)\n",
        "        true_y = true_y.reshape(-1, 1)\n",
        "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
        "\n",
        "def mean_squared_error(pred_y, true_y):\n",
        "    return np.mean(np.square(true_y - pred_y))\n",
        "\n",
        "def differential_1d(f, x):\n",
        "    eps = 1e-5\n",
        "    diff_value = np.zeros_like(x)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        temp_val = x[i]\n",
        "\n",
        "        x[i] = temp_val + eps\n",
        "        f_h1 = f(x)\n",
        "\n",
        "        x[i] = temp_val - eps\n",
        "        f_h2 = f(x)\n",
        "\n",
        "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
        "        x[i] = temp_val\n",
        "    \n",
        "    return diff_value\n",
        "\n",
        "def differential_2d(f, X):\n",
        "    if X.ndim == 1:\n",
        "        return differential_1d(f, X)\n",
        "    else:\n",
        "        temp = np.zeros_like(X)\n",
        "\n",
        "        for idx, x in enumerate(X):\n",
        "            temp[idx] = differential_1d(f, x)\n",
        "        \n",
        "        return temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoV9fyj8_u7"
      },
      "source": [
        "#### 2층 신경망으로 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "XBObD5Fw89HI"
      },
      "outputs": [],
      "source": [
        "class MyModel():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # 가중치 및 편향 생성\n",
        "        def weight_init(input_nodes, hidden_nodes, output_units):\n",
        "            np.random.seed(1)\n",
        "            params = {}\n",
        "            params[\"w_1\"] = 0.01 * np.random.randn(input_nodes, hidden_nodes)\n",
        "            params[\"b_1\"] = np.zeros(hidden_nodes)\n",
        "            params[\"w_2\"] = 0.01 * np.random.randn(hidden_nodes, output_units)\n",
        "            params[\"b_2\"] = np.zeros(output_units)\n",
        "            return params\n",
        "        \n",
        "        # 2층 신경망으로 구성\n",
        "        self.params = weight_init(784, 64, 10)\n",
        "    \n",
        "    # 예측값 생성\n",
        "    def predict(self, x):\n",
        "        W_1, W_2 = self.params[\"w_1\"], self.params[\"w_2\"]\n",
        "        B_1, B_2 = self.params[\"b_1\"], self.params[\"b_2\"]\n",
        "\n",
        "        A1 = np.dot(x, W_1) + B_1\n",
        "        Z1 = sigmoid(A1)\n",
        "\n",
        "        A2 = np.dot(Z1, W_2) + B_2\n",
        "        pred_y = softmax(A2)\n",
        "        return pred_y\n",
        "    \n",
        "    # 정확도 생성\n",
        "    def accuracy(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        y_argmax = np.argmax(pred_y, axis=1)\n",
        "        t_argmax = np.argmax(true_y, axis=1)\n",
        "        accuracy = np.sum(y_argmax == t_argmax) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # 손실(오차) 생성\n",
        "    def loss(self, x, true_y):\n",
        "        pred_y = self.predict(x)\n",
        "        return cross_entropy_error(pred_y, true_y)\n",
        "    \n",
        "    # 기울기 생성\n",
        "    def get_gradient(self, x, true_y):\n",
        "        def loss_grad(grad):\n",
        "            return self.loss(x, true_y)\n",
        "        \n",
        "        grads = {}\n",
        "        grads[\"w_1\"] = differential_2d(loss_grad, self.params[\"w_1\"])\n",
        "        grads[\"w_2\"] = differential_2d(loss_grad, self.params[\"w_2\"])\n",
        "        grads[\"b_1\"] = differential_2d(loss_grad, self.params[\"b_1\"])\n",
        "        grads[\"b_2\"] = differential_2d(loss_grad, self.params[\"b_2\"])\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maKNIlK-xJ5k"
      },
      "source": [
        "#### 모델 생성 및 학습\n",
        "- 시간 많이 소요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "XSEARgNIop8t"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eb47e4f350a430bb1ac32c21ca1d61f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Cost: 1062.6337253552351, Train Accuracy: 0.09871666666666666, Test Accuracy: 0.098, Time: 96.18123507499695\n",
            "Epoch: 2, Cost: 735.7567548048737, Train Accuracy: 0.09736666666666667, Test Accuracy: 0.0982, Time: 172.20519876480103\n"
          ]
        }
      ],
      "source": [
        "model = MyModel()\n",
        "iter_per_epoch = train_size / batch_size\n",
        "\n",
        "start_time = time.time()\n",
        "for i in tqdm(range(epochs)):\n",
        "    batch_idx = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_idx]\n",
        "    y_batch = y_train_ohe[batch_idx]\n",
        "\n",
        "    grads = model.get_gradient(x_batch, y_batch)\n",
        "\n",
        "    for key in grads.keys():\n",
        "        model.params[key] -= lr * grads[key]\n",
        "\n",
        "    loss = model.loss(x_batch, y_batch)\n",
        "    \n",
        "    train_accuracy = model.accuracy(x_train, y_train_ohe)\n",
        "    test_accuracy = model.accuracy(x_test, y_test_ohe)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"Epoch: {}, Cost: {}, Train Accuracy: {}, Test Accuracy: {}, Time: {}\".format(i+1, loss, train_accuracy, test_accuracy, end_time-start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7nL8f20x4zl"
      },
      "source": [
        "### 모델의 결과\n",
        "- 모델은 학습이 잘 될 수도, 잘 안될 수도 있음\n",
        "\n",
        "- 만약, 학습이 잘 되지 않았다면,  \n",
        "  학습이 잘 되기 위해서 어떠한 조치를 취해야 하는가?\n",
        "  - 다양한 학습관련 기술이 존재"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
